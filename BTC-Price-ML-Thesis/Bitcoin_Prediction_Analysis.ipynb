{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7f5ec2-7a38-458d-910a-f40760b05ec4",
   "metadata": {},
   "source": [
    "# Analysis of Machine Learning Effectiveness in Decentralized Financial Markets\n",
    "**Author:** Paweł Winnik  \n",
    "**Project:** Bachelor's Thesis Implementation  \n",
    "**Data Range:** 2015-01-01 to 2023-12-31  \n",
    "\n",
    "## Project Overview\n",
    "The application compares various ML models in predicting Bitcoin price movements using technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb2f97-a923-4288-941a-b4cbddc802b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import talib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURACJA (POPRAWIONA)\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    'ticker': 'BTC-USD',\n",
    "    'period': 'max',\n",
    "    'commission': 0.0015,     # 0.15% prowizji\n",
    "    'initial_capital': 10000, # Kapitał początkowy (np. 10,000 USD) - BRAKUJĄCY KLUCZ DODANY\n",
    "    'test_size': 0.2,         # 20% danych na test\n",
    "}\n",
    "\n",
    "# Parametry wskaźników technicznych \n",
    "PARAMS_DAILY = {\n",
    "    'sma_windows': [5, 10, 20, 50],\n",
    "    'rsi_window': 14,\n",
    "    'macd_fast': 12, 'macd_slow': 26, 'macd_signal': 9,\n",
    "    'volatility_window': 5,\n",
    "    'atr_window': 14\n",
    "}\n",
    "\n",
    "# Ustawienia estetyczne wykresów\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.1)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "MODEL_COLORS = {\n",
    "    'LogisticRegression': '#1f77b4',\n",
    "    'RandomForest': '#2ca02c',\n",
    "    'SVM': '#ff7f0e',\n",
    "    'MLP': '#9467bd',\n",
    "    'LSTM': '#d62728',\n",
    "    'Buy & Hold': '#7f7f7f'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODUŁ WIZUALIZACJI (THESIS READY)\n",
    "# ==========================================\n",
    "class ThesisVisualizer:\n",
    "    def __init__(self, save_dir='plots/'):\n",
    "        self.save_dir = save_dir\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "    def save_and_show(self, filename):\n",
    "        path = os.path.join(self.save_dir, filename)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path, bbox_inches='tight')\n",
    "        print(f\"Zapisano wykres: {path}\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrices(self, results_dict):\n",
    "        \"\"\"Generuje Rys. 53-55\"\"\"\n",
    "        models = [m for m in results_dict.keys() if m != 'Buy & Hold']\n",
    "        n_models = len(models)\n",
    "        cols = 3\n",
    "        rows = (n_models // cols) + (1 if n_models % cols > 0 else 0)\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, model_name in enumerate(models):\n",
    "            if 'cm' in results_dict[model_name]:\n",
    "                cm = results_dict[model_name]['cm']\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False,\n",
    "                            annot_kws={\"size\": 12, \"weight\": \"bold\"})\n",
    "                axes[i].set_title(f'Macierz pomyłek: {model_name}', fontsize=12, weight='bold')\n",
    "                axes[i].set_xlabel('Przewidziana')\n",
    "                axes[i].set_ylabel('Rzeczywista')\n",
    "                axes[i].set_xticklabels(['Spadek', 'Wzrost'])\n",
    "                axes[i].set_yticklabels(['Spadek', 'Wzrost'])\n",
    "        \n",
    "        # Ukrycie pustych osi\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "            \n",
    "        self.save_and_show(\"confusion_matrices.png\")\n",
    "\n",
    "    def plot_metrics_comparison(self, results_df):\n",
    "        \"\"\"Generuje Rys. 58-62\"\"\"\n",
    "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "        df_plot = results_df[results_df['Model'] != 'Buy & Hold'].copy()\n",
    "        \n",
    "        df_melted = df_plot.melt(id_vars='Model', value_vars=metrics, var_name='Metryka', value_name='Wartość')\n",
    "        \n",
    "        plt.figure(figsize=(12, 7))\n",
    "        ax = sns.barplot(x='Metryka', y='Wartość', hue='Model', data=df_melted, palette=MODEL_COLORS, edgecolor='white')\n",
    "        \n",
    "        plt.title('Porównanie skuteczności modeli (Metryki klasyfikacji)', fontsize=14, pad=15)\n",
    "        plt.ylim(0.4, 1.05) # Skalowanie dla lepszej widoczności\n",
    "        plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "        \n",
    "        # Wartości na słupkach\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.2f', padding=3, fontsize=8)\n",
    "            \n",
    "        self.save_and_show(\"metrics_comparison.png\")\n",
    "\n",
    "    def plot_financial_comparison(self, results_df):\n",
    "        \"\"\"Generuje Rys. 56-57\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Sharpe Ratio\n",
    "        sns.barplot(x='Model', y='Sharpe Ratio', data=results_df, ax=axes[0], palette=MODEL_COLORS)\n",
    "        axes[0].set_title('Sharpe Ratio', fontsize=12, weight='bold')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        for container in axes[0].containers:\n",
    "            axes[0].bar_label(container, fmt='%.2f', padding=3)\n",
    "\n",
    "        # Total Return\n",
    "        sns.barplot(x='Model', y='Total Return [%]', data=results_df, ax=axes[1], palette=MODEL_COLORS)\n",
    "        axes[1].set_title('Total Return [%]', fontsize=12, weight='bold')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        for container in axes[1].containers:\n",
    "            axes[1].bar_label(container, fmt='%.1f', padding=3)\n",
    "            \n",
    "        self.save_and_show(\"financial_metrics.png\")\n",
    "\n",
    "    def plot_equity_curves(self, equity_data, dates):\n",
    "        \"\"\"Generuje Rys. 63\"\"\"\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        for model_name, curve in equity_data.items():\n",
    "            color = MODEL_COLORS.get(model_name, '#333333')\n",
    "            # Dopasowanie długości wektora dat do krzywej kapitału\n",
    "            plot_dates = dates[-len(curve):]\n",
    "            plt.plot(plot_dates, curve, label=model_name, linewidth=2, color=color, alpha=0.8)\n",
    "            \n",
    "        plt.title('Symulacja krzywej kapitału (Equity Curve)', fontsize=14, pad=15)\n",
    "        plt.ylabel('Wartość portfela [USD]')\n",
    "        plt.xlabel('Data')\n",
    "        plt.legend()\n",
    "        plt.grid(True, which='major', linestyle='--', alpha=0.6)\n",
    "        self.save_and_show(\"equity_curves.png\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. PRZETWARZANIE DANYCH\n",
    "# ==========================================\n",
    "class DataHandler:\n",
    "    @staticmethod\n",
    "    def get_data(ticker):\n",
    "        print(f\"--> Pobieranie danych dla {ticker}...\")\n",
    "        try:\n",
    "            df = yf.download(ticker, period=\"max\", progress=False)\n",
    "            # Obsługa nowego formatu yfinance (MultiIndex)\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "            \n",
    "            # Jeśli nadal są problemy z indeksowaniem kolumn po dacie\n",
    "            if 'Close' not in df.columns:\n",
    "                print(\"Błąd struktury danych. Sprawdź wersję yfinance.\")\n",
    "                return None\n",
    "                \n",
    "            df = df[['Open', 'High', 'Low', 'Close', 'Volume']].ffill()\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Błąd pobierania danych: {e}\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def add_features(df, p):\n",
    "        data = df.copy()\n",
    "        # Wskaźniki techniczne (TA-Lib)\n",
    "        data['log_return'] = np.log(data['Close'] / data['Close'].shift(1))\n",
    "        data['volatility'] = data['log_return'].rolling(p['volatility_window']).std()\n",
    "        data['atr'] = talib.ATR(data['High'], data['Low'], data['Close'], timeperiod=p['atr_window'])\n",
    "        \n",
    "        for w in p['sma_windows']:\n",
    "            data[f'sma_{w}'] = talib.SMA(data['Close'], timeperiod=w)\n",
    "            \n",
    "        data['rsi'] = talib.RSI(data['Close'], timeperiod=p['rsi_window'])\n",
    "        \n",
    "        macd, macd_sig, _ = talib.MACD(data['Close'], \n",
    "                                       fastperiod=p['macd_fast'], \n",
    "                                       slowperiod=p['macd_slow'], \n",
    "                                       signalperiod=p['macd_signal'])\n",
    "        data['macd'] = macd\n",
    "        data['macd_signal'] = macd_sig\n",
    "        \n",
    "        # Zmienna celu (Target): 1 jeśli Close[t+1] > Close[t]\n",
    "        data['target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
    "        \n",
    "        data.dropna(inplace=True)\n",
    "        return data\n",
    "\n",
    "# ==========================================\n",
    "# 4. BACKTESTING\n",
    "# ==========================================\n",
    "def run_backtest(prices, predictions, initial_capital, commission):\n",
    "    capital = initial_capital\n",
    "    position = 0 \n",
    "    equity_curve = [initial_capital]\n",
    "    \n",
    "    # prices i predictions muszą mieć tę samą długość w pętli\n",
    "    # predictions[i] to decyzja podjęta w dniu i (na podstawie danych do i)\n",
    "    # realizowana po cenie zamknięcia i (lub otwarcia i+1, tu uproszczone do close)\n",
    "    \n",
    "    for i in range(len(predictions) - 1):\n",
    "        curr_price = prices.iloc[i]\n",
    "        next_price = prices.iloc[i+1]\n",
    "        signal = predictions[i]\n",
    "        \n",
    "        # Logika: 1 = Kup/Trzymaj, 0 = Sprzedaj/Gotówka\n",
    "        if signal == 1 and position == 0: \n",
    "            # Kupno za całą gotówkę (pomniejszone o prowizję)\n",
    "            position = (capital * (1 - commission)) / curr_price\n",
    "            capital = 0\n",
    "        elif signal == 0 and position > 0: \n",
    "            # Sprzedaż wszystkiego\n",
    "            capital = position * curr_price * (1 - commission)\n",
    "            position = 0\n",
    "            \n",
    "        # Wycena portfela na koniec dnia\n",
    "        current_equity = capital + (position * next_price)\n",
    "        equity_curve.append(current_equity)\n",
    "        \n",
    "    final_equity = equity_curve[-1]\n",
    "    \n",
    "    # Obliczanie metryk\n",
    "    equity_series = pd.Series(equity_curve)\n",
    "    returns = equity_series.pct_change().dropna()\n",
    "    \n",
    "    total_ret = (final_equity - initial_capital) / initial_capital * 100\n",
    "    sharpe = (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() != 0 else 0\n",
    "    \n",
    "    return total_ret, sharpe, equity_curve\n",
    "\n",
    "# ==========================================\n",
    "# 5. GŁÓWNA PĘTLA (MAIN)\n",
    "# ==========================================\n",
    "def main():\n",
    "    # 1. Pobieranie danych\n",
    "    df_raw = DataHandler.get_data(CONFIG['ticker'])\n",
    "    if df_raw is None: return\n",
    "\n",
    "    # 2. Inżynieria cech\n",
    "    df = DataHandler.add_features(df_raw, PARAMS_DAILY)\n",
    "    \n",
    "    # 3. Podział danych (Train / Test)\n",
    "    split_idx = int(len(df) * (1 - CONFIG['test_size']))\n",
    "    \n",
    "    feature_cols = [c for c in df.columns if c not in ['Open', 'High', 'Low', 'Close', 'Volume', 'target']]\n",
    "    X = df[feature_cols]\n",
    "    y = df['target']\n",
    "    \n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    \n",
    "    # Ceny do backtestu (muszą odpowiadać indeksom X_test)\n",
    "    prices_test = df['Close'].iloc[split_idx:]\n",
    "    dates_test = df.index[split_idx:]\n",
    "    \n",
    "    # Skalowanie\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    results_list = []\n",
    "    equity_curves = {}\n",
    "    full_results_data = {} # Dla macierzy pomyłek\n",
    "    \n",
    "    # --- MODEL REFERENCYJNY: BUY & HOLD ---\n",
    "    # Obliczamy ile kupilibyśmy BTC na początku okresu testowego\n",
    "    initial_btc = (CONFIG['initial_capital'] * (1 - CONFIG['commission'])) / prices_test.iloc[0]\n",
    "    equity_bh = initial_btc * prices_test\n",
    "    \n",
    "    equity_curves['Buy & Hold'] = equity_bh.values\n",
    "    \n",
    "    bh_total_ret = (equity_bh.iloc[-1] - CONFIG['initial_capital']) / CONFIG['initial_capital'] * 100\n",
    "    # Sharpe dla B&H\n",
    "    bh_returns = equity_bh.pct_change().dropna()\n",
    "    bh_sharpe = (bh_returns.mean() / bh_returns.std()) * np.sqrt(252) if bh_returns.std() != 0 else 0\n",
    "\n",
    "    results_list.append({\n",
    "        'Model': 'Buy & Hold',\n",
    "        'Accuracy': 0, 'Precision': 0, 'Recall': 0, 'F1-Score': 0, 'AUC': 0,\n",
    "        'Total Return [%]': bh_total_ret, \n",
    "        'Sharpe Ratio': bh_sharpe\n",
    "    })\n",
    "\n",
    "    # --- MODELE KLASYCZNE (SKLEARN) ---\n",
    "    models_sklearn = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "        'SVM': SVC(probability=True, kernel='rbf', random_state=42)\n",
    "    }\n",
    "    \n",
    "    for name, model in models_sklearn.items():\n",
    "        print(f\"--> Trenowanie modelu: {name}...\")\n",
    "        model.fit(X_train_s, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test_s)\n",
    "        y_prob = model.predict_proba(X_test_s)[:, 1]\n",
    "        \n",
    "        # Metryki ML\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        # Backtest\n",
    "        ret, sharpe, eq_curve = run_backtest(prices_test, y_pred, CONFIG['initial_capital'], CONFIG['commission'])\n",
    "        \n",
    "        results_list.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1, 'AUC': auc,\n",
    "            'Total Return [%]': ret, 'Sharpe Ratio': sharpe\n",
    "        })\n",
    "        equity_curves[name] = eq_curve\n",
    "        full_results_data[name] = {'cm': confusion_matrix(y_test, y_pred)}\n",
    "\n",
    "    # --- MODELE SIECI NEURONOWYCH (KERAS) ---\n",
    "    \n",
    "    # 1. MLP\n",
    "    print(\"--> Trenowanie modelu: MLP...\")\n",
    "    mlp = Sequential([\n",
    "        Input(shape=(X_train_s.shape[1],)),\n",
    "        Dense(64, activation='relu'), Dropout(0.5),\n",
    "        Dense(32, activation='relu'), Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    mlp.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # Early Stopping dla przyspieszenia i uniknięcia overfittingu\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    mlp.fit(X_train_s, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=0, callbacks=[es])\n",
    "    \n",
    "    y_prob_mlp = mlp.predict(X_test_s).flatten()\n",
    "    y_pred_mlp = (y_prob_mlp > 0.5).astype(int)\n",
    "    \n",
    "    ret_mlp, sharpe_mlp, eq_mlp = run_backtest(prices_test, y_pred_mlp, CONFIG['initial_capital'], CONFIG['commission'])\n",
    "    \n",
    "    results_list.append({\n",
    "        'Model': 'MLP',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_mlp),\n",
    "        'Precision': precision_score(y_test, y_pred_mlp, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred_mlp, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test, y_pred_mlp, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_test, y_prob_mlp),\n",
    "        'Total Return [%]': ret_mlp, 'Sharpe Ratio': sharpe_mlp\n",
    "    })\n",
    "    equity_curves['MLP'] = eq_mlp\n",
    "    full_results_data['MLP'] = {'cm': confusion_matrix(y_test, y_pred_mlp)}\n",
    "    \n",
    "    # 2. LSTM\n",
    "    print(\"--> Trenowanie modelu: LSTM...\")\n",
    "    # Reshape pod LSTM [samples, time steps, features]\n",
    "    X_train_lstm = X_train_s.reshape((X_train_s.shape[0], 1, X_train_s.shape[1]))\n",
    "    X_test_lstm = X_test_s.reshape((X_test_s.shape[0], 1, X_test_s.shape[1]))\n",
    "    \n",
    "    lstm = Sequential([\n",
    "        Input(shape=(1, X_train_s.shape[1])),\n",
    "        LSTM(50), Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    lstm.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    lstm.fit(X_train_lstm, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=0, callbacks=[es])\n",
    "    \n",
    "    y_prob_lstm = lstm.predict(X_test_lstm).flatten()\n",
    "    y_pred_lstm = (y_prob_lstm > 0.5).astype(int)\n",
    "    \n",
    "    ret_lstm, sharpe_lstm, eq_lstm = run_backtest(prices_test, y_pred_lstm, CONFIG['initial_capital'], CONFIG['commission'])\n",
    "    \n",
    "    results_list.append({\n",
    "        'Model': 'LSTM',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_lstm),\n",
    "        'Precision': precision_score(y_test, y_pred_lstm, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred_lstm, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test, y_pred_lstm, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_test, y_prob_lstm),\n",
    "        'Total Return [%]': ret_lstm, 'Sharpe Ratio': sharpe_lstm\n",
    "    })\n",
    "    equity_curves['LSTM'] = eq_lstm\n",
    "    full_results_data['LSTM'] = {'cm': confusion_matrix(y_test, y_pred_lstm)}\n",
    "\n",
    "    # ==========================================\n",
    "    # 6. RAPORTOWANIE I WIZUALIZACJA\n",
    "    # ==========================================\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    print(\"\\n=== PODSUMOWANIE WYNIKÓW ===\")\n",
    "    print(df_results.round(4).to_string(index=False))\n",
    "    \n",
    "    print(\"\\nGenerowanie wykresów w folderze /plots...\")\n",
    "    viz = ThesisVisualizer()\n",
    "    \n",
    "    viz.plot_confusion_matrices(full_results_data)\n",
    "    viz.plot_metrics_comparison(df_results)\n",
    "    viz.plot_financial_comparison(df_results)\n",
    "    viz.plot_equity_curves(equity_curves, dates_test)\n",
    "    \n",
    "    print(\"Zakończono pomyślnie.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
